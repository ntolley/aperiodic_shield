{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import sys\n",
    "import pynwb\n",
    "from allensdk.brain_observatory.ecephys.dynamic_gating_ecephys_session import DynamicGatingEcephysSession\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import xarray as xr\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "# include code path\n",
    "sys.path.append('code')\n",
    "\n",
    "# load custom shield scripts\n",
    "from shield_utils import find_animals, get_lfp_dict, downsample, align_lfp, load_animals_oi\n",
    "\n",
    "# paths\n",
    "data_path = '/oscar/data/sjones/kduecker/shield_data'\n",
    "meta_path = 'externals/SHIELD_Dynamic_Gating_Analysis'\n",
    "\n",
    "\n",
    "#for subj_id in range(6):\n",
    "# # subj_id from array job\n",
    "# subj_id = 1\n",
    "\n",
    "subj_id = 1\n",
    "down_srate = 500            # downsampling\n",
    "roi = ['LGd', 'VISp']       # regions of interest\n",
    "toi = [0, 2]                # time window around \n",
    "\n",
    "mice_sess = load_animals_oi()  # load subject and sesson IDs\n",
    "\n",
    "# loop over mice here and store\n",
    "subj = list(mice_sess.keys())[subj_id]\n",
    "\n",
    "ses_files = os.listdir(os.path.join(data_path,f'sub-{subj}'))           # sessions per mouse\n",
    "\n",
    "# get lfp files and spike files\n",
    "lfp_files = list(filter(lambda s: 'None' in s, ses_files))\n",
    "\n",
    "# load the sessions that have the ROIs\n",
    "\n",
    "session = mice_sess[subj][0]\n",
    "ses_file = list(filter(lambda s: session in s, ses_files))\n",
    " \n",
    "#layer_lfp = get_lfp_dict(subj, data_path, lfp_files, ses_file[0], toi, down_srate, roi) # empty...\n",
    "\n",
    "# layer_area_units is empty!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if channel indices for single units and lfp are different (it looks like they are).\n",
    "\n",
    "# sessions of interest\n",
    "\n",
    "lfp_chan = dict()\n",
    "# extract layer for each unit\n",
    "layer_areas_units = dict()\n",
    "\n",
    "single_units = dict()\n",
    "\n",
    "for session in mice_sess[subj]:\n",
    "\n",
    "    # fill in layer areas\n",
    "    layer_areas_units[session] = dict()\n",
    "    lfp_chan[session] = []\n",
    "    single_units[session] = []\n",
    "    ses_file = list(filter(lambda s: session in s, ses_files))\n",
    "    nwb_file_asset = pynwb.NWBHDF5IO(f'{data_path}/sub-{subj}/{ses_file[0]}', mode='r', load_namespaces=True)\n",
    "    nwb_file = nwb_file_asset.read()\n",
    "    dynamic_gating_session = DynamicGatingEcephysSession.from_nwb(nwb_file)\n",
    "\n",
    "    # probe map\n",
    "    probe_index = dynamic_gating_session.probes.index\n",
    "    probe_map = {}\n",
    "    for p in probe_index:\n",
    "        probe_name = dynamic_gating_session.probes.name[p]\n",
    "        filename = list(filter(lambda s: '-'+str(p)+'_' in s, lfp_files))\n",
    "        probe_map[probe_name] = os.path.join(os.path.join(data_path,f'sub-{subj}'),filename[0])\n",
    "\n",
    "    # add the LFP data to the session object\n",
    "    dynamic_gating_session = DynamicGatingEcephysSession.from_nwb(nwb_file, probe_data_path_map=probe_map)\n",
    "\n",
    "    # get the channels\n",
    "    sess_units = dynamic_gating_session.get_units()\n",
    "    single_units[session] = sess_units.index.values\n",
    "\n",
    "    # find the different layers in the brain area (e.g. VISpl2/3. VISl4, VISpl5)\n",
    "\n",
    "    areas = np.unique(sess_units.structure_layer.values)\n",
    "    area_layers = [name for name in areas if any(r in name for r in roi)]\n",
    "\n",
    "    for al in area_layers: \n",
    "        layer_areas_units[session][al] = sess_units[sess_units.structure_layer.str.contains(al)].index\n",
    "\n",
    "    # get stimulus presentations\n",
    "    stim_presentations = dynamic_gating_session.stimulus_presentations\n",
    "    flashes = stim_presentations[stim_presentations['stimulus_name'].str.contains('flash')]\n",
    "    presentation_times = flashes.start_time.values\n",
    "    flash_end_times = presentation_times + flashes.duration\n",
    "    presentation_ids = flashes.index.values\n",
    "\n",
    "    srate = dynamic_gating_session.probes.sampling_rate.values[0]\n",
    "    dt = 1/srate\n",
    "\n",
    "\n",
    "    # load LFP for each probe\n",
    "    for pi in probe_index:\n",
    "        probe_lfp = dynamic_gating_session.get_lfp(pi)\n",
    "        lfp_chan[session].append(probe_lfp.channel.values)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no overlap\n",
      "no overlap\n"
     ]
    }
   ],
   "source": [
    "for session in lfp_chan:\n",
    "    lu = np.concatenate(lfp_chan[session])\n",
    "    su = single_units[session]\n",
    "    if len(np.intersect1d(lu,su)) == 0:\n",
    "        print(f'session {session} no overlap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all sessions\n",
    "\n",
    "lfp_chan = dict()\n",
    "# extract layer for each unit\n",
    "layer_areas_units = dict()\n",
    "\n",
    "single_units = dict()\n",
    "\n",
    "for ses_file in ses_files[:4]:\n",
    "    session = ses_file[ses_file.find('ses-'):ses_file.find('T')+1]\n",
    "    layer_areas_units[session] = dict()\n",
    "    lfp_chan[session] = []\n",
    "    single_units[session] = []\n",
    "    #ses_file = list(filter(lambda s: session in s, ses_files))\n",
    "    nwb_file_asset = pynwb.NWBHDF5IO(f'{data_path}/sub-{subj}/{ses_file}', mode='r', load_namespaces=True)\n",
    "    nwb_file = nwb_file_asset.read()\n",
    "    dynamic_gating_session = DynamicGatingEcephysSession.from_nwb(nwb_file)\n",
    "\n",
    "    # probe map\n",
    "    probe_index = dynamic_gating_session.probes.index\n",
    "    probe_map = {}\n",
    "    for p in probe_index:\n",
    "        probe_name = dynamic_gating_session.probes.name[p]\n",
    "        filename = list(filter(lambda s: '-'+str(p)+'_' in s, lfp_files))\n",
    "        probe_map[probe_name] = os.path.join(os.path.join(data_path,f'sub-{subj}'),filename[0])\n",
    "\n",
    "    # add the LFP data to the session object\n",
    "    dynamic_gating_session = DynamicGatingEcephysSession.from_nwb(nwb_file, probe_data_path_map=probe_map)\n",
    "\n",
    "    # get the channels\n",
    "    sess_units = dynamic_gating_session.get_units()\n",
    "    single_units[session].append(sess_units.index.values)\n",
    "\n",
    "    # find the different layers in the brain area (e.g. VISpl2/3. VISl4, VISpl5)\n",
    "\n",
    "    areas = np.unique(sess_units.structure_layer.values)\n",
    "    area_layers = [name for name in areas if any(r in name for r in roi)]\n",
    "\n",
    "    for al in area_layers: \n",
    "        layer_areas_units[session][al] = sess_units[sess_units.structure_layer.str.contains(al)].index\n",
    "\n",
    "    # get stimulus presentations\n",
    "    stim_presentations = dynamic_gating_session.stimulus_presentations\n",
    "    flashes = stim_presentations[stim_presentations['stimulus_name'].str.contains('flash')]\n",
    "    presentation_times = flashes.start_time.values\n",
    "    flash_end_times = presentation_times + flashes.duration\n",
    "    presentation_ids = flashes.index.values\n",
    "\n",
    "    srate = dynamic_gating_session.probes.sampling_rate.values[0]\n",
    "    dt = 1/srate\n",
    "\n",
    "\n",
    "    # load LFP for each probe\n",
    "    for pi in probe_index:\n",
    "        probe_lfp = dynamic_gating_session.get_lfp(pi)\n",
    "        lfp_chan[session].append(probe_lfp.channel.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session ses-20220926T no overlap\n",
      "session ses-20220927T no overlap\n",
      "session ses-20220928T no overlap\n",
      "session ses-20220929T no overlap\n"
     ]
    }
   ],
   "source": [
    "for session in lfp_chan:\n",
    "    lu = np.concatenate(lfp_chan[session])\n",
    "    su = single_units[session]\n",
    "    if len(np.intersect1d(lu,su)) == 0:\n",
    "        print(f'session {session} no overlap')\n",
    "    else:\n",
    "        print(f'session {session} overlap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub-626279_ses-None_probe-355_ecephys.nwb'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_file[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aperiodic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
